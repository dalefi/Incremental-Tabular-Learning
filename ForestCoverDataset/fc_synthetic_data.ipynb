{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd02517-074f-4114-a6da-b632bac98a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/dfischer/masterarbeit/src/\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import sklearn as skl\n",
    "import _pickle as pickle\n",
    "\n",
    "from ydata_synthetic.synthesizers.regular import RegularSynthesizer\n",
    "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
    "\n",
    "import lib.class_distributions as class_distributions\n",
    "import lib.data_selection as data_selection\n",
    "import lib.helper_funcs as helper_funcs\n",
    "\n",
    "import dtreeviz\n",
    "import logging\n",
    "# to suppress messages when plotting trees\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f350ac6-1424-415c-b54d-f5a212b96efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "\n",
    "data_folder = Path(\"../../data/ForestCoverDataset/\")\n",
    "model_folder = Path(\"../../models/ForestCoverDataset\")\n",
    "file_to_open = data_folder / \"covtype.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed46137d-036e-4413-800c-84d73cc84518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and prepare data\n",
    "\n",
    "data = pd.read_csv(file_to_open, delimiter=\",\", header=None)\n",
    "\n",
    "# add the header manually\n",
    "header = {0: \"Elevation\", 1: \"Aspect\", 2: \"Slope\", 3: \"Horizontal_Distance_To_Hydrology\",\n",
    "          4: \"Vertical_Distance_To_Hydrology\", 5: \"Horizontal_Distance_To_Roadways\",\n",
    "          6: \"Hillshade_9am\", 7: \"Hillshade_Noon\", 8: \"Hillshade_3pm\", 9: \"Horizontal_Distance_To_Fire_Points\"}\n",
    "\n",
    "num_cols = list(header.values())\n",
    "\n",
    "# add the names of binary columns\n",
    "for i in range(1, 5):\n",
    "    header[9+i] = f\"Wilderness_Area_{i}\"\n",
    "\n",
    "for i in range(1, 41):\n",
    "    header[13+i] = f\"Soil_Type_{i}\"\n",
    "\n",
    "header[54] = \"Cover_Type\"\n",
    "\n",
    "cat_cols = list(header.values())[10:]\n",
    "\n",
    "data = data.rename(header, axis=1)\n",
    "\n",
    "# need feature matrix X and labels labels for xgboost\n",
    "labels = data[\"Cover_Type\"]\n",
    "labels = labels - 1   # want 0-based index\n",
    "X = data.drop([\"Cover_Type\"],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303384ab-f2b4-4726-a631-bd7b485cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare smaller dataset with only subset of classes\n",
    "\n",
    "old_classes = [0,1,3,4,5,6]\n",
    "new_class = 2\n",
    "\n",
    "# compute number of old labels used\n",
    "num_labels = len(old_classes)\n",
    "\n",
    "# relabel for XGBoost\n",
    "labels = helper_funcs.relabel(labels, old_classes, new_class)\n",
    "\n",
    "data_small = X[labels < num_labels]\n",
    "labels_small = labels[labels < num_labels]\n",
    "\n",
    "# attempt to retrain with new data\n",
    "data_update = X[labels == num_labels]\n",
    "labels_update = labels[labels == num_labels]\n",
    "\n",
    "# also train a model with all the data availale for comparison\n",
    "data_full = pd.concat([data_small, data_update])\n",
    "labels_full = pd.concat([labels_small, labels_update])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2578def4-f8b7-42e6-a04d-f2b8cb7d7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training parameters\n",
    "batch_size = 500\n",
    "epochs = 500+1\n",
    "learning_rate = 2e-4\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.9\n",
    "\n",
    "ctgan_args = ModelParameters(batch_size=batch_size,\n",
    "                             lr=learning_rate,\n",
    "                             betas=(beta_1, beta_2))\n",
    "\n",
    "train_args = TrainParameters(epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf77b83-d298-4a05-8ada-46572ea7bd4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m synth \u001b[38;5;241m=\u001b[39m RegularSynthesizer(modelname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctgan\u001b[39m\u001b[38;5;124m'\u001b[39m, model_parameters\u001b[38;5;241m=\u001b[39mctgan_args)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msynth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/ydata_synthetic/synthesizers/regular/ctgan/model.py:120\u001b[0m, in \u001b[0;36mCTGAN.fit\u001b[0;34m(self, data, train_arguments, num_cols, cat_cols)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DataFrame, train_arguments: TrainParameters, num_cols: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], cat_cols: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    Fits the CTGAN model.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m        cat_cols: List of columns to be handled as categorical\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_arguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator_optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m    123\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_lr, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_critic_optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m    125\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_lr, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/ydata_synthetic/synthesizers/gan.py:148\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, data, num_cols, cat_cols, train_arguments)\u001b[0m\n\u001b[1;32m    145\u001b[0m     n_clusters \u001b[38;5;241m=\u001b[39m train_arguments\u001b[38;5;241m.\u001b[39mn_clusters\n\u001b[1;32m    146\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m train_arguments\u001b[38;5;241m.\u001b[39mepsilon\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mCTGANDataProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m--> 148\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA DataProcessor is not available for the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__MODEL__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/sklearn/utils/_testing.py:188\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    187\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory)\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/ydata_synthetic/preprocessing/regular/ctgan_processor.py:111\u001b[0m, in \u001b[0;36mCTGANDataProcessor.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     bgm \u001b[38;5;241m=\u001b[39m BayesianGaussianMixture(\n\u001b[1;32m    106\u001b[0m         n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_clusters,\n\u001b[1;32m    107\u001b[0m         weight_concentration_prior_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirichlet_process\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    108\u001b[0m         weight_concentration_prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m    109\u001b[0m         n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mbgm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     components \u001b[38;5;241m=\u001b[39m bgm\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epsilon\n\u001b[1;32m    113\u001b[0m     output_dim \u001b[38;5;241m=\u001b[39m components\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/sklearn/mixture/_base.py:186\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/sklearn/mixture/_base.py:252\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    250\u001b[0m     prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[0;32m--> 252\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_m_step(X, log_resp)\n\u001b[1;32m    254\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/sklearn/mixture/_base.py:309\u001b[0m, in \u001b[0;36mBaseMixture._e_step\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"E step.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m        the point of each sample in X.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(log_prob_norm), log_resp\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/sklearn/mixture/_base.py:530\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03mCompute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m    logarithm of the responsibilities\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m weighted_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_weighted_log_prob(X)\n\u001b[0;32m--> 530\u001b[0m log_prob_norm \u001b[38;5;241m=\u001b[39m \u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_log_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n\u001b[1;32m    533\u001b[0m     log_resp \u001b[38;5;241m=\u001b[39m weighted_log_prob \u001b[38;5;241m-\u001b[39m log_prob_norm[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/scipy/special/_logsumexp.py:111\u001b[0m, in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    109\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(a \u001b[38;5;241m-\u001b[39m a_max)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# suppress warnings about log of zero\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "synth = RegularSynthesizer(modelname='ctgan', model_parameters=ctgan_args)\n",
    "synth.fit(data=data_full, train_arguments=train_args, num_cols=num_cols, cat_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df2917-5360-4dd7-806c-5fe6990ecc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data = synth.sample(1000)\n",
    "print(synth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7467bb-6478-41dc-b93b-69446d105aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_master",
   "language": "python",
   "name": "env_master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
