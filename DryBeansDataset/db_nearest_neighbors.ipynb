{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec79d30-23e0-41f9-a1b7-048123586a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import sklearn as skl\n",
    "import _pickle as pickle\n",
    "\n",
    "from mylib import class_distributions\n",
    "from mylib import data_selection\n",
    "from mylib import helper_funcs\n",
    "\n",
    "import dtreeviz\n",
    "import logging\n",
    "# to suppress messages when plotting trees\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e79ae48-4831-45f4-854f-c4ff8b34aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "\n",
    "data_folder = Path(\"../../../data/DryBeanDataset/\")\n",
    "model_folder = Path(\"../../../models/DryBeanDataset\")\n",
    "file_to_open = data_folder / \"Dry_Bean_Dataset.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea248c5-3156-4cf5-bbe6-874ba1bf5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and prepare data\n",
    "\n",
    "data = pd.read_excel(file_to_open)\n",
    "\n",
    "labels_dict = {key:value for (value,key) in enumerate(data[\"Class\"].unique())}\n",
    "data[\"Class\"] = data[\"Class\"].map(labels_dict)\n",
    "#data.Class.astype(\"category\").cat.codes\n",
    "\n",
    "# need feature matrix X and labels labels for xgboost\n",
    "labels = data[\"Class\"]\n",
    "X = data.drop([\"Class\"],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5895d5c3-d533-4e0d-b20c-ab3ca6bbce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    0.260525\n",
       "5    0.193667\n",
       "0    0.148924\n",
       "4    0.141650\n",
       "3    0.119756\n",
       "1    0.097127\n",
       "2    0.038351\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distributions.label_proportions(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bc49fd-2abd-4c94-8b78-6abd8ff21580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare smaller dataset with only first num_labels classes of beans\n",
    "\n",
    "old_classes = [0,1,3,4,5,6]\n",
    "new_class = 2\n",
    "\n",
    "# compute number of old labels used\n",
    "num_labels = len(old_classes)\n",
    "\n",
    "# relabel for XGBoost\n",
    "labels = helper_funcs.relabel(labels, old_classes, new_class)\n",
    "\n",
    "data_small = X[labels < num_labels]\n",
    "labels_small = labels[labels < num_labels]\n",
    "\n",
    "# attempt to retrain with new data\n",
    "new_class_data = X[labels == num_labels]\n",
    "new_class_labels = labels[labels == num_labels]\n",
    "\n",
    "# also train a model with all the data availale for comparison\n",
    "data_full = pd.concat([data_small, new_class_data])\n",
    "labels_full = pd.concat([labels_small, new_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414570f2-62ba-483e-9210-ef5b22076c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train- and test-data\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = skl.model_selection.train_test_split(data_small, \n",
    "                                                    labels_small,\n",
    "                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3a162a-f7a7-480e-8156-f3e1cad70140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify DMatrices\n",
    "\n",
    "dtrain_small = xgb.DMatrix(X_train_small, label=y_train_small)\n",
    "dtest_small = xgb.DMatrix(X_test_small, label=y_test_small)\n",
    "\n",
    "# specify some parameters\n",
    "num_models = 10\n",
    "proportion_of_old_data = [i*0.1 for i in range(1,10)]\n",
    "\n",
    "# specify paramters for XGBoost\n",
    "num_round = 100\n",
    "num_round_full = 2*num_round   # a more apt comparison I think\n",
    "early_stopping_rounds = num_round*.1\n",
    "max_depth = 3\n",
    "eta = .1\n",
    "\n",
    "param_small = {'max_depth': max_depth, 'eta': eta, 'objective': 'multi:softprob', \"num_class\": num_labels}\n",
    "param_small['nthread'] = 4\n",
    "param_small['eval_metric'] = 'mlogloss'\n",
    "\n",
    "evallist_small = [(dtrain_small, 'train'), (dtest_small, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c16aec-2b99-4cf6-b770-555d1cf315ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.56619\teval-mlogloss:1.57072\n",
      "[25]\ttrain-mlogloss:0.32024\teval-mlogloss:0.35110\n",
      "[50]\ttrain-mlogloss:0.19905\teval-mlogloss:0.23705\n",
      "[75]\ttrain-mlogloss:0.16812\teval-mlogloss:0.21243\n",
      "[99]\ttrain-mlogloss:0.15333\teval-mlogloss:0.20453\n"
     ]
    }
   ],
   "source": [
    "# training model with fewer labels\n",
    "bst_small = xgb.train(param_small,\n",
    "                      dtrain_small,\n",
    "                      num_round,\n",
    "                      evals=evallist_small,\n",
    "                      #early_stopping_rounds=early_stopping_rounds,\n",
    "                      verbose_eval=25)\n",
    "\n",
    "bst_small.save_model(fname=model_folder / 'small_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de024086-343f-4411-a67f-38f862bbd5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.9243697478991597\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data: \", skl.metrics.accuracy_score(np.argmax(bst_small.predict(dtest_small), axis=1), y_test_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceaf1f4b-8a4c-4473-81c8-f82ccfc306f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Area': 173.0,\n",
       " 'Perimeter': 256.0,\n",
       " 'MajorAxisLength': 162.0,\n",
       " 'MinorAxisLength': 191.0,\n",
       " 'AspectRation': 170.0,\n",
       " 'ConvexArea': 179.0,\n",
       " 'Extent': 293.0,\n",
       " 'Solidity': 322.0,\n",
       " 'roundness': 410.0,\n",
       " 'Compactness': 384.0,\n",
       " 'ShapeFactor1': 385.0,\n",
       " 'ShapeFactor2': 99.0,\n",
       " 'ShapeFactor4': 569.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_small.get_fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e1c7da-bf36-466e-95a4-3a55538c273f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Compactness', 0.8503294711809524),\n",
       " ('ShapeFactor1', 0.0061881079500000005),\n",
       " ('ConvexArea', 56172.95238095238),\n",
       " ('Compactness', 0.7600958175390071),\n",
       " ('MajorAxisLength', 285.557258140625),\n",
       " ('ConvexArea', 38900.9125)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_small_df = bst_small.trees_to_dataframe()\n",
    "data_selection.important_features_by_class(bst_small_df, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f47c5dcd-8230-41cf-b980-d65aca570c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train- and test-data\n",
    "\n",
    "X_train_new_class, X_test_new_class, y_train_new_class, y_test_new_class = skl.model_selection.train_test_split(new_class_data,\n",
    "                                                                                                                new_class_labels,\n",
    "                                                                                                                test_size=.3,\n",
    "                                                                                                                random_state=2)\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = skl.model_selection.train_test_split(data_full,\n",
    "                                                                                            labels_full,\n",
    "                                                                                            test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d945750-f2c9-426d-bc07-b10a4e2bc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify DMatrices\n",
    "\n",
    "# only to check performance on the newly added data\n",
    "dtrain_new_class = xgb.DMatrix(new_class_data, label=new_class_labels)\n",
    "\n",
    "dtrain_full = xgb.DMatrix(X_train_full, label=y_train_full)\n",
    "dtest_full = xgb.DMatrix(X_test_full, label=y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4740d23a-e811-468a-a6e9-a83748dbd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for data_full model\n",
    "\n",
    "param_full = {'max_depth': max_depth,\n",
    "              'eta': eta,\n",
    "              'objective': 'multi:softprob',\n",
    "              \"num_class\": num_labels+1}\n",
    "param_full['nthread'] = 4\n",
    "param_full['eval_metric'] = 'mlogloss'\n",
    "\n",
    "evallist_full = [(dtrain_full, 'train'), (dtest_full, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0196056-357d-4c6a-8f9f-49840628f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.68470\teval-mlogloss:1.68676\n",
      "[25]\ttrain-mlogloss:0.32986\teval-mlogloss:0.35262\n",
      "[50]\ttrain-mlogloss:0.19646\teval-mlogloss:0.22863\n",
      "[75]\ttrain-mlogloss:0.16380\teval-mlogloss:0.20446\n",
      "[100]\ttrain-mlogloss:0.14744\teval-mlogloss:0.19596\n",
      "[125]\ttrain-mlogloss:0.13644\teval-mlogloss:0.19356\n",
      "[150]\ttrain-mlogloss:0.12723\teval-mlogloss:0.19273\n",
      "[175]\ttrain-mlogloss:0.11931\teval-mlogloss:0.19247\n",
      "[199]\ttrain-mlogloss:0.11242\teval-mlogloss:0.19160\n"
     ]
    }
   ],
   "source": [
    "# training a model with all the training data\n",
    "\n",
    "bst_full = xgb.train(param_full,\n",
    "                     dtrain_full,\n",
    "                     num_round_full,\n",
    "                     evals=evallist_full,\n",
    "                     #early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=25)\n",
    "\n",
    "bst_full.save_model(fname=model_folder / 'small_model_full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "293ac1e9-85bc-4d5f-875a-19c58879b9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.9283878075651855\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data: \", skl.metrics.accuracy_score(np.argmax(bst_full.predict(dtest_full), axis=1), y_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e713955-8ee2-4b4e-a8eb-bc2e17fe5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for update model (the same as for full model, but just in case I want to ever change them)\n",
    "\n",
    "param_update = {'max_depth': max_depth,\n",
    "                'eta': eta,\n",
    "                'objective': 'multi:softprob',\n",
    "                \"num_class\": num_labels+1}\n",
    "param_update['nthread'] = 4\n",
    "param_update['eval_metric'] = 'mlogloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c03094-1b84-46af-a105-f9f679b7e40d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 45\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m     37\u001b[0m bst_update \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(param_update,\n\u001b[1;32m     38\u001b[0m                           dtrain_update,\n\u001b[1;32m     39\u001b[0m                           num_round,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m                           xgb_model\u001b[38;5;241m=\u001b[39mmodel_folder\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall_model.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m random_old_tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m skl\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mbst_update\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtest_small\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_test_small)\n\u001b[1;32m     46\u001b[0m random_new_tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m skl\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(np\u001b[38;5;241m.\u001b[39margmax(bst_update\u001b[38;5;241m.\u001b[39mpredict(dtest_update), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_test_update)\n\u001b[1;32m     47\u001b[0m random_mixed_tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m skl\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(np\u001b[38;5;241m.\u001b[39margmax(bst_update\u001b[38;5;241m.\u001b[39mpredict(dtest_update), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_test_update)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/xgboost/core.py:2164\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2161\u001b[0m shape \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(c_bst_ulong)()\n\u001b[1;32m   2162\u001b[0m dims \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m   2163\u001b[0m _check_call(\n\u001b[0;32m-> 2164\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_pystr_to_cstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2172\u001b[0m )\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_old = []\n",
    "random_new = []\n",
    "random_mixed = []\n",
    "random_full = []\n",
    "\n",
    "\n",
    "for proportion in proportion_of_old_data:\n",
    "    print(f\"Current target proportion of old data in use: {proportion}\")\n",
    "    \n",
    "    random_old_tmp = 0\n",
    "    random_new_tmp = 0\n",
    "    random_mixed_tmp = 0\n",
    "    random_full_tmp = 0\n",
    "\n",
    "    for _ in range(num_models):\n",
    "\n",
    "        _, old_data_part, _, old_y_part = skl.model_selection.train_test_split(data_small,\n",
    "                                                                               labels_small,\n",
    "                                                                               test_size=proportion)\n",
    "        \n",
    "\n",
    "        data_update = pd.concat([old_data_part, new_class_data])\n",
    "        labels_update = pd.concat([old_y_part, new_class_labels])\n",
    "\n",
    "        X_train_update, X_test_update, y_train_update, y_test_update = skl.model_selection.train_test_split(data_update,\n",
    "                                                                                                            labels_update,\n",
    "                                                                                                            test_size=.2)\n",
    "\n",
    "        # create DMatrices\n",
    "\n",
    "        dtrain_update = xgb.DMatrix(X_train_update, label=y_train_update)\n",
    "        dtest_update = xgb.DMatrix(X_test_update, label=y_test_update)\n",
    "        \n",
    "        evallist_update = [(dtrain_update, 'train'), (dtest_update, 'eval')]\n",
    "\n",
    "        # train model\n",
    "        bst_update = xgb.train(param_update,\n",
    "                                  dtrain_update,\n",
    "                                  num_round,\n",
    "                                  evals=evallist_update,\n",
    "                                  #early_stopping_rounds=early_stopping_rounds,\n",
    "                                  verbose_eval=False,\n",
    "                                  xgb_model=model_folder/\"small_model.json\")\n",
    "\n",
    "        random_old_tmp += skl.metrics.accuracy_score(np.argmax(bst_update.predict(dtest_small), axis=1), y_test_small)\n",
    "        random_new_tmp += skl.metrics.accuracy_score(np.argmax(bst_update.predict(dtest_update), axis=1), y_test_update)\n",
    "        random_mixed_tmp += skl.metrics.accuracy_score(np.argmax(bst_update.predict(dtest_update), axis=1), y_test_update)\n",
    "        random_full_tmp += skl.metrics.accuracy_score(np.argmax(bst_update.predict(dtest_full), axis=1), y_test_full)\n",
    "        \n",
    "    random_old.append(random_old_tmp/num_models)\n",
    "    random_new.append(random_new_tmp/num_models)    \n",
    "    random_mixed.append(random_mixed_tmp/num_models)    \n",
    "    random_full.append(random_full_tmp/num_models)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d14ebaec-20bc-4129-bbdf-5da733b0d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n",
      "Current target proportion of old data in use: 0.30000000000000004\n",
      "Current target proportion of old data in use: 0.4\n",
      "Current target proportion of old data in use: 0.5\n",
      "Current target proportion of old data in use: 0.6000000000000001\n",
      "Current target proportion of old data in use: 0.7000000000000001\n",
      "Current target proportion of old data in use: 0.8\n",
      "Current target proportion of old data in use: 0.9\n",
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n",
      "Current target proportion of old data in use: 0.30000000000000004\n",
      "Current target proportion of old data in use: 0.4\n",
      "Current target proportion of old data in use: 0.5\n",
      "Current target proportion of old data in use: 0.6000000000000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m dtest_critical \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test_critical, label\u001b[38;5;241m=\u001b[39my_test_critical)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# updating the model with the new class\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m bst_critical \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdtrain_critical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevallist_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_folder\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msmall_model.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m critical_old_tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m skl\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(np\u001b[38;5;241m.\u001b[39margmax(bst_critical\u001b[38;5;241m.\u001b[39mpredict(dtest_small), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_test_small)\n\u001b[1;32m     55\u001b[0m critical_new_tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m skl\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(np\u001b[38;5;241m.\u001b[39margmax(bst_critical\u001b[38;5;241m.\u001b[39mpredict(dtest_update), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_test_update)\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/masterarbeit/env_master/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "critical_old_alphas = {}\n",
    "critical_new_alphas = {}\n",
    "critical_mixed_alphas = {}\n",
    "critical_full_alphas = {}\n",
    "\n",
    "for alpha in [.2*i for i in range(6)]:\n",
    "\n",
    "    critical_old = []\n",
    "    critical_new = []\n",
    "    critical_mixed = []\n",
    "    critical_full = []\n",
    "\n",
    "    for proportion in proportion_of_old_data:\n",
    "        print(f\"Current target proportion of old data in use: {proportion}\")\n",
    "\n",
    "        # get critical data\n",
    "        critical_data, critical_data_labels = data_selection.get_samples_nearest_neighbors(data_small,\n",
    "                                                                                              labels_small,\n",
    "                                                                                              new_class_data,\n",
    "                                                                                              ratio_return_total = proportion,\n",
    "                                                                                              normalization=\"min_max\",\n",
    "                                                                                              alpha=alpha,\n",
    "                                                                                              remove_duplicates=False)\n",
    "\n",
    "\n",
    "\n",
    "        # concatenate with data for new class\n",
    "        critical_data = pd.concat([critical_data, data_update])\n",
    "        critical_data_labels = pd.concat([critical_data_labels, labels_update])\n",
    "\n",
    "        # train a model with the new class and the critical data\n",
    "        critical_old_tmp = 0\n",
    "        critical_new_tmp = 0\n",
    "        critical_mixed_tmp = 0\n",
    "        critical_full_tmp = 0\n",
    "\n",
    "        for i in range(num_models):\n",
    "            X_train_critical, X_test_critical, y_train_critical, y_test_critical = skl.model_selection.train_test_split(critical_data,\n",
    "                                                                                                                        critical_data_labels,\n",
    "                                                                                                                        test_size=.2)\n",
    "\n",
    "            dtrain_critical = xgb.DMatrix(X_train_critical, label=y_train_critical)\n",
    "            dtest_critical = xgb.DMatrix(X_test_critical, label=y_test_critical)\n",
    "\n",
    "            # updating the model with the new class\n",
    "            bst_critical = xgb.train(param_update,\n",
    "                                      dtrain_critical,\n",
    "                                      num_round,\n",
    "                                      evals=evallist_update,\n",
    "                                      early_stopping_rounds=early_stopping_rounds,\n",
    "                                      verbose_eval=False,\n",
    "                                      xgb_model=model_folder/\"small_model.json\")\n",
    "\n",
    "            critical_old_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_small), axis=1), y_test_small)\n",
    "            critical_new_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_update), axis=1), y_test_update)\n",
    "            critical_mixed_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_critical), axis=1), y_test_critical)\n",
    "            critical_full_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_full), axis=1), y_test_full)\n",
    "\n",
    "        critical_old.append(critical_old_tmp/num_models)\n",
    "        critical_new.append(critical_new_tmp/num_models)\n",
    "        critical_mixed.append(critical_mixed_tmp/num_models)\n",
    "        critical_full.append(critical_full_tmp/num_models)\n",
    "    \n",
    "    critical_old_alphas[f\"{alpha}\"] = critical_old\n",
    "    critical_new_alphas[f\"{alpha}\"] = critical_new\n",
    "    critical_mixed_alphas[f\"{alpha}\"] = critical_mixed\n",
    "    critical_full_alphas[f\"{alpha}\"] = critical_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8586982-8716-4416-ac0b-f49c442bbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the performances\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0.8, 1])\n",
    "plt.title(f\"NearestNeighbors, minmax, including duplicates, train smallest class\")\n",
    "plt.plot(proportion_of_old_data, random_full, label=\"model updated with random data\")\n",
    "for key in critical_full_alphas.keys():\n",
    "    plt.plot(proportion_of_old_data, critical_full_alphas[key], label=f\"model updated with critical data (alpha={key:.3})\")\n",
    "    \n",
    "plt.axhline(skl.metrics.accuracy_score(np.argmax(bst_full.predict(dtest_full), axis=1), y_test_full),\n",
    "            color = \"black\",\n",
    "            linestyle = \"--\",\n",
    "            label = \"batch training on full data\")\n",
    "plt.xlabel(\"Percentage of old data used in updating\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(f\"NN, minmax, including duplicates, train smallest class.png\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_master",
   "language": "python",
   "name": "env_master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
