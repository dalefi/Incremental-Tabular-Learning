{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269340bd-4291-4e78-b006-6560a693301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 22:20:58.110897: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 22:20:58.216571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/teradata/client/14.10/lib\n",
      "2023-04-27 22:20:58.216591: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-27 22:20:58.763755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/teradata/client/14.10/lib\n",
      "2023-04-27 22:20:58.763942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/teradata/client/14.10/lib\n",
      "2023-04-27 22:20:58.763950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/dfischer/masterarbeit/src/\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import sklearn as skl\n",
    "import _pickle as pickle\n",
    "\n",
    "from ydata_synthetic.synthesizers.regular import RegularSynthesizer\n",
    "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
    "\n",
    "from mylib import class_distributions\n",
    "from mylib import data_selection\n",
    "from mylib import helper_funcs\n",
    "\n",
    "import dtreeviz\n",
    "import logging\n",
    "# to suppress messages when plotting trees\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a8eea1-43cf-421a-b665-b336eab77931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "\n",
    "data_folder = Path(\"../../data/DryBeanDataset/\")\n",
    "model_folder = Path(\"../../models/DryBeanDataset\")\n",
    "file_to_open = data_folder / \"Dry_Bean_Dataset.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7372dd-a058-4b16-a704-d6f09cd8eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and prepare data\n",
    "\n",
    "data = pd.read_excel(file_to_open)\n",
    "\n",
    "labels_dict = {key:value for (value,key) in enumerate(data[\"Class\"].unique())}\n",
    "data[\"Class\"] = data[\"Class\"].map(labels_dict)\n",
    "#data.Class.astype(\"category\").cat.codes\n",
    "\n",
    "# need feature matrix X and labels labels for xgboost\n",
    "labels = data[\"Class\"]\n",
    "X = data.drop([\"Class\"],axis=1,inplace=False)\n",
    "\n",
    "num_cols = list(data.columns[:16])\n",
    "cat_cols = list(data.columns[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850c5dc9-d936-46a6-b3d1-7d02f42f35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare smaller dataset with only first num_labels classes of beans\n",
    "\n",
    "old_classes = [0,1,3,4,5,6]\n",
    "new_class = 2\n",
    "\n",
    "# compute number of old labels used\n",
    "num_labels = len(old_classes)\n",
    "\n",
    "# relabel for XGBoost\n",
    "labels = helper_funcs.relabel(labels, old_classes, new_class)\n",
    "\n",
    "data_small = X[labels < num_labels]\n",
    "labels_small = labels[labels < num_labels]\n",
    "\n",
    "# attempt to retrain with new data\n",
    "data_update = X[labels == num_labels]\n",
    "labels_update = labels[labels == num_labels]\n",
    "\n",
    "# also train a model with all the data availale for comparison\n",
    "data_full = pd.concat([data_small, data_update])\n",
    "labels_full = pd.concat([labels_small, labels_update])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc45d484-3dff-45ac-8385-60ee22d95cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training parameters\n",
    "batch_size = 500\n",
    "epochs = 100+1\n",
    "learning_rate = 2e-4\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.9\n",
    "\n",
    "ctgan_args = ModelParameters(batch_size=batch_size,\n",
    "                             lr=learning_rate,\n",
    "                             betas=(beta_1, beta_2))\n",
    "\n",
    "train_args = TrainParameters(epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3f2618-99a0-4e40-bf45-22bf07809907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 22:21:02.232565: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-27 22:21:02.232596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-server\n",
      "2023-04-27 22:21:02.232602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-server\n",
      "2023-04-27 22:21:02.232683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 520.56.6\n",
      "2023-04-27 22:21:02.232706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.56.6\n",
      "2023-04-27 22:21:02.232711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 520.56.6\n",
      "2023-04-27 22:21:29.534502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | critic_loss: 0.17191067337989807 | generator_loss: -0.9156926870346069\n",
      "Epoch: 1 | critic_loss: -1.4283976554870605 | generator_loss: -0.761842668056488\n",
      "Epoch: 2 | critic_loss: -1.5370874404907227 | generator_loss: -0.5966498851776123\n",
      "Epoch: 3 | critic_loss: -1.5672193765640259 | generator_loss: 1.073550820350647\n",
      "Epoch: 4 | critic_loss: -2.5383293628692627 | generator_loss: 2.1424639225006104\n",
      "Epoch: 5 | critic_loss: -3.9207956790924072 | generator_loss: 3.551234483718872\n",
      "Epoch: 6 | critic_loss: -4.756309509277344 | generator_loss: 4.070196628570557\n",
      "Epoch: 7 | critic_loss: -5.963504791259766 | generator_loss: 4.606064796447754\n",
      "Epoch: 8 | critic_loss: -7.768545150756836 | generator_loss: 4.980936050415039\n",
      "Epoch: 9 | critic_loss: -8.151101112365723 | generator_loss: 5.341215133666992\n",
      "Epoch: 10 | critic_loss: -8.854833602905273 | generator_loss: 5.521848201751709\n",
      "Epoch: 11 | critic_loss: -11.654335021972656 | generator_loss: 6.0599164962768555\n",
      "Epoch: 12 | critic_loss: -12.67726993560791 | generator_loss: 6.162560939788818\n",
      "Epoch: 13 | critic_loss: -13.623160362243652 | generator_loss: 6.316709518432617\n",
      "Epoch: 14 | critic_loss: -15.390645980834961 | generator_loss: 6.7268571853637695\n",
      "Epoch: 15 | critic_loss: -17.16787338256836 | generator_loss: 7.048184394836426\n",
      "Epoch: 16 | critic_loss: -17.70490074157715 | generator_loss: 6.953953266143799\n",
      "Epoch: 17 | critic_loss: -19.25168228149414 | generator_loss: 7.533288478851318\n",
      "Epoch: 18 | critic_loss: -22.30743980407715 | generator_loss: 7.456315994262695\n",
      "Epoch: 19 | critic_loss: -24.782320022583008 | generator_loss: 8.097426414489746\n",
      "Epoch: 20 | critic_loss: -24.13709259033203 | generator_loss: 7.613865852355957\n",
      "Epoch: 21 | critic_loss: -27.206523895263672 | generator_loss: 8.176925659179688\n",
      "Epoch: 22 | critic_loss: -28.03502655029297 | generator_loss: 8.479870796203613\n",
      "Epoch: 23 | critic_loss: -30.87092399597168 | generator_loss: 8.944889068603516\n",
      "Epoch: 24 | critic_loss: -32.269554138183594 | generator_loss: 8.886663436889648\n",
      "Epoch: 25 | critic_loss: -36.9920654296875 | generator_loss: 9.387829780578613\n",
      "Epoch: 26 | critic_loss: -38.04801940917969 | generator_loss: 9.191720962524414\n",
      "Epoch: 27 | critic_loss: -37.6685791015625 | generator_loss: 9.967801094055176\n",
      "Epoch: 28 | critic_loss: -41.14377975463867 | generator_loss: 9.615384101867676\n",
      "Epoch: 29 | critic_loss: -43.243247985839844 | generator_loss: 10.08330249786377\n",
      "Epoch: 30 | critic_loss: -47.553646087646484 | generator_loss: 9.848498344421387\n",
      "Epoch: 31 | critic_loss: -46.61546325683594 | generator_loss: 10.222887992858887\n",
      "Epoch: 32 | critic_loss: -50.95744323730469 | generator_loss: 10.860280990600586\n",
      "Epoch: 33 | critic_loss: -56.74770736694336 | generator_loss: 10.702261924743652\n",
      "Epoch: 34 | critic_loss: -57.1451416015625 | generator_loss: 11.052787780761719\n",
      "Epoch: 35 | critic_loss: -58.02446746826172 | generator_loss: 10.873464584350586\n",
      "Epoch: 36 | critic_loss: -60.959266662597656 | generator_loss: 11.180716514587402\n",
      "Epoch: 37 | critic_loss: -63.75260925292969 | generator_loss: 11.226917266845703\n",
      "Epoch: 38 | critic_loss: -62.121788024902344 | generator_loss: 11.6865873336792\n",
      "Epoch: 39 | critic_loss: -71.46183776855469 | generator_loss: 12.116466522216797\n",
      "Epoch: 40 | critic_loss: -69.67322540283203 | generator_loss: 12.060315132141113\n",
      "Epoch: 41 | critic_loss: -73.6683578491211 | generator_loss: 12.60021686553955\n",
      "Epoch: 42 | critic_loss: -75.31912231445312 | generator_loss: 12.66927719116211\n",
      "Epoch: 43 | critic_loss: -81.42750549316406 | generator_loss: 12.874293327331543\n",
      "Epoch: 44 | critic_loss: -81.403076171875 | generator_loss: 12.656004905700684\n",
      "Epoch: 45 | critic_loss: -87.07614135742188 | generator_loss: 13.374249458312988\n",
      "Epoch: 46 | critic_loss: -87.07235717773438 | generator_loss: 13.634779930114746\n",
      "Epoch: 47 | critic_loss: -87.01017761230469 | generator_loss: 13.888479232788086\n",
      "Epoch: 48 | critic_loss: -91.60868072509766 | generator_loss: 14.084366798400879\n",
      "Epoch: 49 | critic_loss: -95.24546813964844 | generator_loss: 14.679051399230957\n",
      "Epoch: 50 | critic_loss: -101.44158172607422 | generator_loss: 14.240325927734375\n",
      "Epoch: 51 | critic_loss: -105.93745422363281 | generator_loss: 14.542555809020996\n",
      "Epoch: 52 | critic_loss: -111.961181640625 | generator_loss: 15.096563339233398\n",
      "Epoch: 53 | critic_loss: -106.06790924072266 | generator_loss: 14.602716445922852\n",
      "Epoch: 54 | critic_loss: -112.71685791015625 | generator_loss: 14.918378829956055\n",
      "Epoch: 55 | critic_loss: -106.18785095214844 | generator_loss: 15.489628791809082\n",
      "Epoch: 56 | critic_loss: -116.29238891601562 | generator_loss: 14.735672950744629\n",
      "Epoch: 57 | critic_loss: -119.69892120361328 | generator_loss: 15.73762321472168\n",
      "Epoch: 58 | critic_loss: -124.75748443603516 | generator_loss: 16.39094352722168\n",
      "Epoch: 59 | critic_loss: -128.83078002929688 | generator_loss: 16.078834533691406\n",
      "Epoch: 60 | critic_loss: -136.970458984375 | generator_loss: 16.63056182861328\n",
      "Epoch: 61 | critic_loss: -134.55587768554688 | generator_loss: 16.296571731567383\n",
      "Epoch: 62 | critic_loss: -141.2764129638672 | generator_loss: 17.138877868652344\n",
      "Epoch: 63 | critic_loss: -148.1756591796875 | generator_loss: 17.16581153869629\n",
      "Epoch: 64 | critic_loss: -147.67556762695312 | generator_loss: 17.52973175048828\n",
      "Epoch: 65 | critic_loss: -164.60903930664062 | generator_loss: 17.855953216552734\n",
      "Epoch: 66 | critic_loss: -155.31735229492188 | generator_loss: 17.885908126831055\n",
      "Epoch: 67 | critic_loss: -157.28640747070312 | generator_loss: 17.2111759185791\n",
      "Epoch: 68 | critic_loss: -162.41116333007812 | generator_loss: 18.007701873779297\n",
      "Epoch: 69 | critic_loss: -165.60768127441406 | generator_loss: 18.01125717163086\n",
      "Epoch: 70 | critic_loss: -168.55172729492188 | generator_loss: 18.874038696289062\n",
      "Epoch: 71 | critic_loss: -171.55209350585938 | generator_loss: 18.203767776489258\n",
      "Epoch: 72 | critic_loss: -169.47230529785156 | generator_loss: 18.843629837036133\n",
      "Epoch: 73 | critic_loss: -169.49468994140625 | generator_loss: 18.95760726928711\n",
      "Epoch: 74 | critic_loss: -190.09857177734375 | generator_loss: 19.283714294433594\n",
      "Epoch: 75 | critic_loss: -193.15858459472656 | generator_loss: 19.892431259155273\n",
      "Epoch: 76 | critic_loss: -204.42555236816406 | generator_loss: 19.49599838256836\n",
      "Epoch: 77 | critic_loss: -185.61917114257812 | generator_loss: 19.963340759277344\n",
      "Epoch: 78 | critic_loss: -202.28372192382812 | generator_loss: 19.7037296295166\n",
      "Epoch: 79 | critic_loss: -206.314453125 | generator_loss: 20.55483627319336\n",
      "Epoch: 80 | critic_loss: -210.50201416015625 | generator_loss: 20.13351821899414\n",
      "Epoch: 81 | critic_loss: -244.90573120117188 | generator_loss: 20.650297164916992\n",
      "Epoch: 82 | critic_loss: -215.63137817382812 | generator_loss: 20.236186981201172\n",
      "Epoch: 83 | critic_loss: -231.45376586914062 | generator_loss: 21.1396484375\n",
      "Epoch: 84 | critic_loss: -214.4298095703125 | generator_loss: 20.624326705932617\n",
      "Epoch: 85 | critic_loss: -232.41160583496094 | generator_loss: 20.814241409301758\n",
      "Epoch: 86 | critic_loss: -218.21324157714844 | generator_loss: 22.42816925048828\n",
      "Epoch: 87 | critic_loss: -250.7135467529297 | generator_loss: 22.76516342163086\n",
      "Epoch: 88 | critic_loss: -231.20822143554688 | generator_loss: 22.065258026123047\n",
      "Epoch: 89 | critic_loss: -250.3903045654297 | generator_loss: 22.352083206176758\n",
      "Epoch: 90 | critic_loss: -243.68685913085938 | generator_loss: 21.94339370727539\n",
      "Epoch: 91 | critic_loss: -255.29476928710938 | generator_loss: 22.4448299407959\n",
      "Epoch: 92 | critic_loss: -247.22003173828125 | generator_loss: 22.550893783569336\n",
      "Epoch: 93 | critic_loss: -264.6920471191406 | generator_loss: 23.261011123657227\n",
      "Epoch: 94 | critic_loss: -277.1544494628906 | generator_loss: 23.439695358276367\n",
      "Epoch: 95 | critic_loss: -271.2911071777344 | generator_loss: 24.113784790039062\n",
      "Epoch: 96 | critic_loss: -284.2449951171875 | generator_loss: 23.200210571289062\n",
      "Epoch: 97 | critic_loss: -286.1249694824219 | generator_loss: 23.306907653808594\n",
      "Epoch: 98 | critic_loss: -286.0994567871094 | generator_loss: 23.44591522216797\n",
      "Epoch: 99 | critic_loss: -315.940185546875 | generator_loss: 24.856138229370117\n",
      "Epoch: 100 | critic_loss: -290.29132080078125 | generator_loss: 23.64242935180664\n"
     ]
    }
   ],
   "source": [
    "synth = RegularSynthesizer(modelname='ctgan', model_parameters=ctgan_args)\n",
    "synth.fit(data=data, train_arguments=train_args, num_cols=num_cols, cat_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9d0d7a-eaeb-4c1b-80ea-5abdb678b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetical dataset of the same size as original\n",
    "dataset_synth = synth.sample(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf55566-3f6f-4401-a0cc-92ee4f9626d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_synth = dataset_synth[\"Class\"]\n",
    "data_synth = dataset_synth.drop([\"Class\"],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56096c5-5767-4934-b08c-a328159bb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train- and test-data\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = skl.model_selection.train_test_split(data_small, \n",
    "                                                    labels_small,\n",
    "                                                    test_size=.2)\n",
    "\n",
    "X_train_synth, X_test_synth, y_train_synth, y_test_synth = skl.model_selection.train_test_split(data_synth, \n",
    "                                                    labels_synth,\n",
    "                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f80129-4858-4f0a-8ae9-c55e6a0ae3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify DMatrices\n",
    "\n",
    "dtrain_small = xgb.DMatrix(X_train_small, label=y_train_small)\n",
    "dtest_small = xgb.DMatrix(X_test_small, label=y_test_small)\n",
    "\n",
    "dtrain_synth = xgb.DMatrix(X_train_synth, label=y_train_synth)\n",
    "dtest_synth = xgb.DMatrix(X_test_synth, label=y_test_synth)\n",
    "\n",
    "# specify some parameters\n",
    "num_models = 1\n",
    "proportion_of_old_data = [i*0.1 for i in range(1,10)]\n",
    "\n",
    "# specify paramters for XGBoost\n",
    "num_round = 100\n",
    "early_stopping_rounds = num_round*.1\n",
    "max_depth = 3\n",
    "eta = .1\n",
    "\n",
    "param_small = {'max_depth': max_depth, 'eta': eta, 'objective': 'multi:softprob', \"num_class\": num_labels}\n",
    "param_small['nthread'] = 4\n",
    "param_small['eval_metric'] = 'mlogloss'\n",
    "\n",
    "evallist_small = [(dtrain_small, 'train'), (dtest_small, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b40dd8e8-7e1f-4b21-a131-18d48965334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.56737\teval-mlogloss:1.56855\n",
      "[25]\ttrain-mlogloss:0.32334\teval-mlogloss:0.33876\n",
      "[50]\ttrain-mlogloss:0.20089\teval-mlogloss:0.22924\n",
      "[75]\ttrain-mlogloss:0.16895\teval-mlogloss:0.21131\n",
      "[99]\ttrain-mlogloss:0.15316\teval-mlogloss:0.20598\n"
     ]
    }
   ],
   "source": [
    "# training model with fewer labels\n",
    "bst_small = xgb.train(param_small,\n",
    "                      dtrain_small,\n",
    "                      num_round,\n",
    "                      evals=evallist_small,\n",
    "                      early_stopping_rounds=early_stopping_rounds,\n",
    "                      verbose_eval=25)\n",
    "\n",
    "bst_small.save_model(fname=model_folder / 'fewer_class_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c335a883-30b5-49cc-9d67-b03b78882fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.9251336898395722\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data: \", skl.metrics.accuracy_score(np.argmax(bst_small.predict(dtest_small), axis=1), y_test_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11d5151-bbbb-4ac6-a6d9-3058c96dfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train- and test-data\n",
    "\n",
    "X_train_update, X_test_update, y_train_update, y_test_update = skl.model_selection.train_test_split(data_update,\n",
    "                                                                                                    labels_update,\n",
    "                                                                                                    test_size=.2)\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = skl.model_selection.train_test_split(data_full,\n",
    "                                                                                            labels_full,\n",
    "                                                                                            test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253206e9-1240-4bce-bfaa-bfbb20eb75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify DMatrices\n",
    "\n",
    "dtrain_update = xgb.DMatrix(X_train_update, label=y_train_update)\n",
    "dtest_update = xgb.DMatrix(X_test_update, label=y_test_update)\n",
    "\n",
    "dtrain_full = xgb.DMatrix(X_train_full, label=y_train_full)\n",
    "dtest_full = xgb.DMatrix(X_test_full, label=y_test_full)\n",
    "\n",
    "\n",
    "# specify paramters for XGBoost\n",
    "param_update = {'max_depth': max_depth,\n",
    "                'eta': eta,\n",
    "                'objective': 'multi:softprob',\n",
    "                \"num_class\": num_labels+1}\n",
    "param_update['nthread'] = 4\n",
    "param_update['eval_metric'] = 'mlogloss'\n",
    "\n",
    "evallist_update = [(dtrain_update, 'train'), (dtest_update, 'eval')]\n",
    "\n",
    "\n",
    "param_full = {'max_depth': max_depth,\n",
    "              'eta': eta,\n",
    "              'objective': 'multi:softprob',\n",
    "              \"num_class\": num_labels+1}\n",
    "param_full['nthread'] = 4\n",
    "param_full['eval_metric'] = 'mlogloss'\n",
    "\n",
    "evallist_full = [(dtrain_full, 'train'), (dtest_full, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c86859-a042-436d-aec9-4e04b3955abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.68416\teval-mlogloss:1.69019\n",
      "[25]\ttrain-mlogloss:0.32455\teval-mlogloss:0.36716\n",
      "[50]\ttrain-mlogloss:0.19310\teval-mlogloss:0.24378\n",
      "[75]\ttrain-mlogloss:0.16037\teval-mlogloss:0.21732\n",
      "[99]\ttrain-mlogloss:0.14447\teval-mlogloss:0.20930\n"
     ]
    }
   ],
   "source": [
    "# training a model with all the training data\n",
    "\n",
    "bst_full = xgb.train(param_full,\n",
    "                     dtrain_full,\n",
    "                     num_round,\n",
    "                     evals=evallist_full,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3813fe36-ecf6-41c9-a116-b1d77e2ff281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.9206757253029747\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data: \", skl.metrics.accuracy_score(np.argmax(bst_full.predict(dtest_full), axis=1), y_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31330505-6051-4d08-99d6-b0ab46091c94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bst_synth \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241m.\u001b[39mtrain(param_full,\n\u001b[1;32m      2\u001b[0m                      dtrain_synth,\n\u001b[1;32m      3\u001b[0m                      num_round,\n\u001b[1;32m      4\u001b[0m                      evals\u001b[38;5;241m=\u001b[39mevallist_full,\n\u001b[1;32m      5\u001b[0m                      early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m      6\u001b[0m                      verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "bst_synth = xgb.train(param_full,\n",
    "                     dtrain_synth,\n",
    "                     num_round,\n",
    "                     evals=evallist_full,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dd1d1da-ca32-442b-82f2-5ed9f2d83033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.08409842085934631\n"
     ]
    }
   ],
   "source": [
    "# accuracy of synth-model on actual data\n",
    "\n",
    "print(\"Accuracy on test data: \", skl.metrics.accuracy_score(np.argmax(bst_synth.predict(dtest_full), axis=1), y_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb2623a-2dac-4222-8d4a-5e129ddf623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.1421226588321704\n"
     ]
    }
   ],
   "source": [
    "# accuracy of actual model on synth data\n",
    "\n",
    "print(\"Accuracy on test data: \", skl.metrics.accuracy_score(np.argmax(bst_full.predict(dtest_synth), axis=1), y_test_synth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f116d-5b05-4e43-a5b3-b3386a68fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model with fewer labels\n",
    "bst_synth = xgb.train(param_small,\n",
    "                      dtrain_synth,\n",
    "                      num_round,\n",
    "                      evals=evallist_small,\n",
    "                      early_stopping_rounds=early_stopping_rounds,\n",
    "                      verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c9da2-5230-4376-b78f-bc4d3c0deb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_old = []\n",
    "critical_new = []\n",
    "critical_mixed = []\n",
    "critical_full = []\n",
    "\n",
    "for proportion in proportion_of_old_data:\n",
    "    print(f\"Current target proportion of old data in use: {proportion}\")\n",
    "\n",
    "    # get critical data\n",
    "    critical_data, critical_data_labels = data_selection.get_samples_nearest_neighbors(data_small,\n",
    "                                                                                          labels_small,\n",
    "                                                                                          data_update,\n",
    "                                                                                          ratio_return_total = proportion,\n",
    "                                                                                          normalization=\"min_max\",\n",
    "                                                                                          alpha=alpha,\n",
    "                                                                                          remove_duplicates=False)\n",
    "\n",
    "\n",
    "\n",
    "    # concatenate with data for new class\n",
    "    critical_data = pd.concat([critical_data, data_update])\n",
    "    critical_data_labels = pd.concat([critical_data_labels, labels_update])\n",
    "\n",
    "    # train a model with the new class and the critical data\n",
    "    critical_old_tmp = 0\n",
    "    critical_new_tmp = 0\n",
    "    critical_mixed_tmp = 0\n",
    "    critical_full_tmp = 0\n",
    "\n",
    "    for i in range(num_models):\n",
    "        X_train_critical, X_test_critical, y_train_critical, y_test_critical = skl.model_selection.train_test_split(critical_data,\n",
    "                                                                                                                    critical_data_labels,\n",
    "                                                                                                                    test_size=.2)\n",
    "\n",
    "        dtrain_critical = xgb.DMatrix(X_train_critical, label=y_train_critical)\n",
    "        dtest_critical = xgb.DMatrix(X_test_critical, label=y_test_critical)\n",
    "\n",
    "        # updating the model with the new class\n",
    "        bst_critical = xgb.train(param_update,\n",
    "                                  dtrain_critical,\n",
    "                                  num_round,\n",
    "                                  evals=evallist_update,\n",
    "                                  early_stopping_rounds=early_stopping_rounds,\n",
    "                                  verbose_eval=False,\n",
    "                                  xgb_model=model_folder/\"fewer_class_model.json\")\n",
    "\n",
    "        critical_old_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_small), axis=1), y_test_small)\n",
    "        critical_new_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_update), axis=1), y_test_update)\n",
    "        critical_mixed_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_critical), axis=1), y_test_critical)\n",
    "        critical_full_tmp += skl.metrics.accuracy_score(np.argmax(bst_critical.predict(dtest_full), axis=1), y_test_full)\n",
    "\n",
    "    critical_old.append(critical_old_tmp/num_models)\n",
    "    critical_new.append(critical_new_tmp/num_models)\n",
    "    critical_mixed.append(critical_mixed_tmp/num_models)\n",
    "    critical_full.append(critical_full_tmp/num_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1807c628-c02a-4629-82b0-a47d34ef5d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a1c9b16-b4dd-4225-821d-449192a8e441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13611"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6357605-1682-4b23-a5e4-eaa1ba036282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
