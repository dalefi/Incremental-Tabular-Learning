{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f090e1d-08ee-45dd-8941-0052fce8738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from mylib import helper_funcs\n",
    "from mylib import class_distributions\n",
    "\n",
    "from mylib.pipelines import full_models\n",
    "from mylib.pipelines import updating_pipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb9b45eb-cf69-42a9-bb56-c9a1ad48c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('../../../data/AdultDataset/')\n",
    "data_file = 'adult.data'\n",
    "name_file = 'adult.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fb6314-746d-4b82-b737-31b51f689c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_folder / data_file, delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c9916e-fbcd-4c0c-992e-f9ffb8d78c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the header manually\n",
    "header = {0: \"age\", 1: \"workclass\", 2: \"fnlwgt\", 3: \"education\",\n",
    "          4: \"education-num\", 5: \"marital-status\",\n",
    "          6: \"occupation\", 7: \"relationship\", 8: \"race\", 9: \"sex\",\n",
    "          10: \"capital-gain\", 11: \"capital-loss\", 12: 'hours-per-week',\n",
    "          13: 'native-country', 14: 'income'}\n",
    "\n",
    "data = data.rename(header, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d01683-e7a6-4010-8300-c2c850c91bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_column = 'marital-status'\n",
    "\n",
    "data = data.rename(columns={class_column: 'Class'})\n",
    "data = helper_funcs.create_numbered_categories(data, 'Class')\n",
    "\n",
    "for column in data.columns:\n",
    "    if column not in ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']:\n",
    "        data = helper_funcs.create_numbered_categories(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d26d8b-0401-4e54-a7c5-ae3bbbaad8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.459937\n",
       "0    0.328092\n",
       "2    0.136452\n",
       "4    0.031479\n",
       "6    0.030497\n",
       "3    0.012837\n",
       "5    0.000706\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distributions.label_proportions(data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf69c4f-699c-4240-bb12-691283f43744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_folder / 'AdultDataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327d60a7-679f-4d7f-a8c9-dce72964a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = data_folder / 'AdultDataset.csv'\n",
    "data_selection_method = 'entropy'\n",
    "new_class_idx = 1\n",
    "num_models = 3\n",
    "num_round = 20\n",
    "max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9768ef2-31e5-4fc6-b40c-00ab22945215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training full models in preparation to add class 1 using the continued_training training method\n",
      "Accuracy of full model on old data:  0.735513221495593\n",
      "Accuracy of full model on new data:  0.9859330484330484\n",
      "Accuracy of full model on full data:  0.8440042990941193\n",
      "Adding class 1 with continued_training\n",
      "Used data selection method: entropy. Sort type: closest\n",
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n",
      "Current target proportion of old data in use: 0.30000000000000004\n",
      "Current target proportion of old data in use: 0.4\n",
      "Current target proportion of old data in use: 0.5\n",
      "Current target proportion of old data in use: 0.6000000000000001\n",
      "Current target proportion of old data in use: 0.7000000000000001\n",
      "Current target proportion of old data in use: 0.8\n",
      "Current target proportion of old data in use: 0.9\n",
      "Training full models in preparation to add class 1 using the continued_training training method\n",
      "Accuracy of full model on old data:  0.735513221495593\n",
      "Accuracy of full model on new data:  0.9859330484330484\n",
      "Accuracy of full model on full data:  0.8440042990941193\n",
      "Adding class 1 with continued_training\n",
      "Used data selection method: entropy. Sort type: furthest\n",
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n",
      "Current target proportion of old data in use: 0.30000000000000004\n",
      "Current target proportion of old data in use: 0.4\n",
      "Current target proportion of old data in use: 0.5\n",
      "Current target proportion of old data in use: 0.6000000000000001\n",
      "Current target proportion of old data in use: 0.7000000000000001\n",
      "Current target proportion of old data in use: 0.8\n",
      "Current target proportion of old data in use: 0.9\n",
      "Training full models in preparation to add class 1 using the add_trees training method\n",
      "Accuracy of full model on old data:  0.7296370012321107\n",
      "Accuracy of full model on new data:  0.9856436965811967\n",
      "Accuracy of full model on full data:  0.844516096013102\n",
      "Adding class 1 with add_trees\n",
      "Used data selection method: entropy. Sort type: closest\n",
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n",
      "Current target proportion of old data in use: 0.30000000000000004\n",
      "Current target proportion of old data in use: 0.4\n",
      "Current target proportion of old data in use: 0.5\n",
      "Current target proportion of old data in use: 0.6000000000000001\n",
      "Current target proportion of old data in use: 0.7000000000000001\n",
      "Current target proportion of old data in use: 0.8\n",
      "Current target proportion of old data in use: 0.9\n",
      "Training full models in preparation to add class 1 using the add_trees training method\n",
      "Accuracy of full model on old data:  0.7296370012321107\n",
      "Accuracy of full model on new data:  0.9856436965811967\n",
      "Accuracy of full model on full data:  0.844516096013102\n",
      "Adding class 1 with add_trees\n",
      "Used data selection method: entropy. Sort type: furthest\n",
      "Current target proportion of old data in use: 0.1\n",
      "Current target proportion of old data in use: 0.2\n",
      "Current target proportion of old data in use: 0.30000000000000004\n",
      "Current target proportion of old data in use: 0.4\n",
      "Current target proportion of old data in use: 0.5\n",
      "Current target proportion of old data in use: 0.6000000000000001\n",
      "Current target proportion of old data in use: 0.7000000000000001\n",
      "Current target proportion of old data in use: 0.8\n",
      "Current target proportion of old data in use: 0.9\n"
     ]
    }
   ],
   "source": [
    "for training_method in ['continued_training', 'add_trees']:\n",
    "    for sort_type in ['closest', 'furthest']:\n",
    "\n",
    "        full_models.full_models(filepath,\n",
    "                                training_method,\n",
    "                                new_class_idx,\n",
    "                                num_models,\n",
    "                                num_round,\n",
    "                                max_depth)\n",
    "        \n",
    "        updating_pipeline.updating_pipeline(filepath,\n",
    "                                              training_method,\n",
    "                                              new_class_idx,\n",
    "                                              data_selection_method,\n",
    "                                              sort_type,\n",
    "                                              num_models,\n",
    "                                              num_round,\n",
    "                                              max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b931c7-ee29-49b4-b437-14530b5a9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_or_smallest_class = 'largest class'\n",
    "\n",
    "for training_method in ['continued_training', 'add_trees']:\n",
    "    batch_results = helper_funcs.unpack_batch_results(\"continued_training\", largest_or_smallest_class)\n",
    "\n",
    "\n",
    "    for sort_type in ['closest', 'furthest']:\n",
    "        experiment_results = helper_funcs.unpack_results(\"continued_training\", 'entropy', sort_type, largest_or_smallest_class)\n",
    "        helper_funcs.plot_results(\"continued_training\", experiment_results, batch_results, 'entropy', sort_type, largest_or_smallest_class, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_master",
   "language": "python",
   "name": "env_master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
